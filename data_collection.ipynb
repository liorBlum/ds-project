{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Data Collection"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The data used in this project is taken from [\"Spotify Million Playlist Dataset Challenge\"](https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge) - a continuation of a data science research challenge focused on music recommendation organized by Spotify (See [RecSys Challenge 2018](http://www.recsyschallenge.com/2018/)).\r\n",
                "\r\n",
                "* Another music recommendation challenge that we've considered to base our work on is <https://www.kaggle.com/c/msdchallenge/overview>. However, due to its old age (2012), smaller scale and rigit data formats, the former dataset was preferred."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The project's data consists of:\r\n",
                "1. spotify_million_playlist_dataset (the challenge dataset)\r\n",
                "2. songs_dataset\r\n",
                "3. audio_features_dataset\r\n",
                "4. lyrics_corpus"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## spotify_million_playlist_dataset\r\n",
                "\r\n",
                "### The raw challenge dataset downloaded from <https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge/dataset_files>).\r\n",
                "\r\n",
                "* 1 million playlists consisting of over 2 million unique tracks by nearly 300,000 artists. Created by US Spotify users between January 2010 and November 2017. This dataset is separated into multiple JSON files, each containing 1000 playlists. **Used for both the training set and the test set**"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import json\r\n",
                "\r\n",
                "# Show format of one playlist and one track\r\n",
                "with open('data/spotify_million_playlist_dataset/mpd.slice.0-999.json') as f:\r\n",
                "    ex_playlist = json.load(f)['playlists'][0]\r\n",
                "    ex_playlist['tracks'] = [ex_playlist['tracks'][0]]\r\n",
                "\r\n",
                "ex_playlist"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'name': 'Throwbacks',\n",
                            " 'collaborative': 'false',\n",
                            " 'pid': 0,\n",
                            " 'modified_at': 1493424000,\n",
                            " 'num_tracks': 52,\n",
                            " 'num_albums': 47,\n",
                            " 'num_followers': 1,\n",
                            " 'tracks': [{'pos': 0,\n",
                            "   'artist_name': 'Missy Elliott',\n",
                            "   'track_uri': 'spotify:track:0UaMYEvWZi0ZqiDOoHU3YI',\n",
                            "   'artist_uri': 'spotify:artist:2wIVse2owClT7go1WT98tk',\n",
                            "   'track_name': 'Lose Control (feat. Ciara & Fat Man Scoop)',\n",
                            "   'album_uri': 'spotify:album:6vV5UrXcfyQD1wu4Qo2I9K',\n",
                            "   'duration_ms': 226863,\n",
                            "   'album_name': 'The Cookbook'}],\n",
                            " 'num_edits': 6,\n",
                            " 'duration_ms': 11532414,\n",
                            " 'num_artists': 37}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 1
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## songs_dataset.json \r\n",
                "### All songs from the playlists dataset collected with the following code:"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import json\r\n",
                "import os\r\n",
                "\r\n",
                "all_songs = {}\r\n",
                "spotify_dataset_path = 'data/spotify_million_playlist_dataset/'\r\n",
                "\r\n",
                "# Add all songs from a Spotify slice file (from dataset) to all_songs.json\r\n",
                "def add_all_songs_from_file(path):\r\n",
                "    with open(path) as f:\r\n",
                "        data = json.load(f)\r\n",
                "        \r\n",
                "    for playlist in data['playlists']:\r\n",
                "        for track in playlist['tracks']:\r\n",
                "            track_id = track['track_uri'].partition('spotify:track:')[-1]\r\n",
                "            artist_id = track['artist_uri'].partition('spotify:artist:')[-1]\r\n",
                "            if track_id not in all_songs:\r\n",
                "                all_songs[track_id] = {\r\n",
                "                    'track_name': track['track_name'], \r\n",
                "                    'artist_name': track['artist_name'], \r\n",
                "                    'artist_id': artist_id\r\n",
                "                }\r\n",
                "\r\n",
                "for slice_file in os.listdir(spotify_dataset_path):\r\n",
                "    add_all_songs_from_file(spotify_dataset_path + slice_file)\r\n",
                "with open('data/all_songs.json', 'w') as f:\r\n",
                "    json.dump(all_songs, f)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "import pandas as pd\r\n",
                "\r\n",
                "# Demonstration of the file's format\r\n",
                "all_songs_df = pd.read_json('data/all_songs.json').T\r\n",
                "all_songs_df.head()"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "                                                        track_name  \\\n",
                            "0UaMYEvWZi0ZqiDOoHU3YI  Lose Control (feat. Ciara & Fat Man Scoop)   \n",
                            "6I9VzXrHxO9rA9A5euc8Ak                                       Toxic   \n",
                            "0WqIKmW4BTrj3eJFmnCKMv                               Crazy In Love   \n",
                            "1AWQoqb9bSvzTjaLralEkT                              Rock Your Body   \n",
                            "1lzr43nnXAijIGYnCT8M8H                                It Wasn't Me   \n",
                            "\n",
                            "                              artist_name               artist_id  \n",
                            "0UaMYEvWZi0ZqiDOoHU3YI      Missy Elliott  2wIVse2owClT7go1WT98tk  \n",
                            "6I9VzXrHxO9rA9A5euc8Ak     Britney Spears  26dSoYclwsYLMAKD3tpOr4  \n",
                            "0WqIKmW4BTrj3eJFmnCKMv            Beyoncé  6vWDO969PvNqNYHIOW5v0m  \n",
                            "1AWQoqb9bSvzTjaLralEkT  Justin Timberlake  31TPClRtHm23RisEBtV3X7  \n",
                            "1lzr43nnXAijIGYnCT8M8H             Shaggy  5EvFsr3kj42KNv97ZEnqij  "
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>track_name</th>\n",
                            "      <th>artist_name</th>\n",
                            "      <th>artist_id</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0UaMYEvWZi0ZqiDOoHU3YI</th>\n",
                            "      <td>Lose Control (feat. Ciara &amp; Fat Man Scoop)</td>\n",
                            "      <td>Missy Elliott</td>\n",
                            "      <td>2wIVse2owClT7go1WT98tk</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6I9VzXrHxO9rA9A5euc8Ak</th>\n",
                            "      <td>Toxic</td>\n",
                            "      <td>Britney Spears</td>\n",
                            "      <td>26dSoYclwsYLMAKD3tpOr4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>0WqIKmW4BTrj3eJFmnCKMv</th>\n",
                            "      <td>Crazy In Love</td>\n",
                            "      <td>Beyoncé</td>\n",
                            "      <td>6vWDO969PvNqNYHIOW5v0m</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1AWQoqb9bSvzTjaLralEkT</th>\n",
                            "      <td>Rock Your Body</td>\n",
                            "      <td>Justin Timberlake</td>\n",
                            "      <td>31TPClRtHm23RisEBtV3X7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1lzr43nnXAijIGYnCT8M8H</th>\n",
                            "      <td>It Wasn't Me</td>\n",
                            "      <td>Shaggy</td>\n",
                            "      <td>5EvFsr3kj42KNv97ZEnqij</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 4
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## audio_features_dataset.json\r\n",
                "\r\n",
                "### Various audio features collection generated out of 'songs_dataset'. \r\n",
                "### Retrieved from Spotify public API (<https://api.spotify.com/>)."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# TODO"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## lyrics_corpus.json\r\n",
                "### Lyrics collection of many of the songs from the playlists dataset. Scraped from Genius Lyrics site and public API (<https://genius.com/>).\r\n",
                "\r\n",
                "* [Note: The full code (lyrics_list_builder.py) also searched for missing URLs to obtain as many lyrics as possible]"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import aiohttp\r\n",
                "import asyncio\r\n",
                "import time\r\n",
                "import json\r\n",
                "from lyrics_scraper import url, lyrics # based on code from https://github.com/johnwmillr/LyricsGenius\r\n",
                "import unicodedata\r\n",
                "import re\r\n",
                "\r\n",
                "asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\r\n",
                "\r\n",
                "all_urls = []\r\n",
                "all_require_search = []\r\n",
                "all_lyrics = {}\r\n",
                "\r\n",
                "# Build Genius URLs dictionary\r\n",
                "\r\n",
                "print('Building all_urls list...')\r\n",
                "start_time = time.time()\r\n",
                "\r\n",
                "def parse_name(name):\r\n",
                "    s = unicodedata.normalize('NFKD', name).encode('ascii','ignore').decode('utf8')\r\n",
                "    s = re.search(r'([^()\\[\\]-]*)', s).group(1).strip().replace(' ', '-').replace('&', 'and')\r\n",
                "    return re.sub('[^a-zA-Z0-9_\\-]', '', s)\r\n",
                "\r\n",
                "with open('data/songs_dataset.json', 'r') as songs_file:\r\n",
                "    with open('data/lyrics1-100000.json', 'r') as lyrics_file:\r\n",
                "        all_songs = json.load(songs_file)\r\n",
                "        all_lyrics = json.load(lyrics_file)\r\n",
                "        assert type(all_lyrics) == dict\r\n",
                "        assert type(all_songs) == dict\r\n",
                "        counter = 0\r\n",
                "        for track_id, track_data in all_songs.items():\r\n",
                "            # Limit number of songs\r\n",
                "            if counter >= 100000:\r\n",
                "                break\r\n",
                "            counter += 1\r\n",
                "            # Don't fetch lyrics we already have\r\n",
                "            if all_lyrics.get(track_id):\r\n",
                "                continue\r\n",
                "            parsed_track_name = parse_name(track_data['track_name'])\r\n",
                "            parsed_artist_name = parse_name(track_data['artist_name'])\r\n",
                "            if parsed_artist_name and parsed_track_name:\r\n",
                "                all_urls.append((track_id, track_data, \r\n",
                "                    f'https://genius.com/{parsed_artist_name}-{parsed_track_name}-lyrics'))\r\n",
                "                \r\n",
                "            else:\r\n",
                "                all_require_search.append((track_id, track_data))\r\n",
                "            \r\n",
                "\r\n",
                "print(f'len(all_urls) equals {len(all_urls)}')\r\n",
                "print(\"--- URLs list building took %s seconds ---\" % (time.time() - start_time))\r\n",
                "\r\n",
                "# Build lyrics list with asynchronous HTTP requests to genius.com\r\n",
                "\r\n",
                "async def get_lyrics(session, url, track_id, track_name):\r\n",
                "    try:\r\n",
                "        async with session.get(url, timeout=5) as resp:\r\n",
                "            if (resp.status == 200):\r\n",
                "                lyrics_html = await resp.text()\r\n",
                "                return (track_id, track_name + '\\n' + lyrics(lyrics_html, True))\r\n",
                "            else:\r\n",
                "                print(f'Received status {resp.status} for {url}') if resp.status != 404 else None\r\n",
                "                return (track_id, None)\r\n",
                "    except Exception as e:\r\n",
                "        return (track_id, None)\r\n",
                "\r\n",
                "songs_lyrics_list = []\r\n",
                "\r\n",
                "async def add_to_lyrics_list(urls_list, songs_offsets=(0, None)):\r\n",
                "    \"\"\" Try to retrieve lyrics from given URLs \"\"\"\r\n",
                "    global songs_lyrics_list\r\n",
                "\r\n",
                "    async with aiohttp.ClientSession() as session:\r\n",
                "        tasks = []\r\n",
                "\r\n",
                "        print(f'Retrieving lyrics of songs {songs_offsets[0]}:{songs_offsets[1]}...')\r\n",
                "        for track_id, track_data, url in urls_list[songs_offsets[0]:songs_offsets[1]]:\r\n",
                "            tasks.append(asyncio.ensure_future(get_lyrics(session, url, track_id, track_data['track_name'])))\r\n",
                "\r\n",
                "        songs_lyrics_list += await asyncio.gather(*tasks)\r\n",
                "        \r\n",
                "\r\n",
                "total_songs_num = len(all_urls)\r\n",
                "songs_at_each_interval = 200\r\n",
                "\r\n",
                "start_time = time.time()\r\n",
                "print('Retrieving lyrics from URLs found in all_urls...')\r\n",
                "for i in range(0, total_songs_num, songs_at_each_interval):\r\n",
                "    asyncio.run(add_to_lyrics_list(all_urls, (i, i + songs_at_each_interval)))\r\n",
                "    time.sleep(0.2)\r\n",
                "end_time = time.time()\r\n",
                "print(\"--- Lyrics retrieval took %s seconds ---\" % (end_time - start_time))\r\n",
                "\r\n",
                "for track_id, track_lyrics in songs_lyrics_list:\r\n",
                "    if not track_lyrics:\r\n",
                "        all_require_search.append((track_id, all_songs[track_id]))\r\n",
                "\r\n",
                "songs_lyrics_list = [(track_id, lyrics) for (track_id, lyrics) in songs_lyrics_list if lyrics]\r\n",
                "print(f'Retrieved lyrics of {len(songs_lyrics_list)} songs')\r\n",
                "\r\n",
                "start_time = time.time()\r\n",
                "file_path = 'data/lyrics_corpus.json'\r\n",
                "with open(file_path, 'w') as f:\r\n",
                "    all_lyrics.update({track_id: lyrics for (track_id, lyrics) in songs_lyrics_list if lyrics})\r\n",
                "    json.dump(all_lyrics, f)\r\n",
                "print(f\"Added lyrics for {len(songs_lyrics_list)} songs to {file_path}\")\r\n",
                "print(\"--- Lyrics file writing took %s seconds ---\" % (end_time - start_time))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "* Some tracks are instrumental, and for some others lyrics were unavailable. The lyrics_Corpus only contains entries of songs with existing and obtainable lyrics. \r\n",
                "* Out of the 100,000 tracks which we use, we managed to obtain lyrics for about 78% of them. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "import json\r\n",
                "\r\n",
                "with open('data/lyrics_corpus.json', 'r') as lyrics_file:\r\n",
                "    all_lyrics = json.load(lyrics_file)\r\n",
                "\r\n",
                "print(f'lyrics_corpus contains {len(all_lyrics.values())} songs')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "lyrics_corpus contains 78130 songs\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.8 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "3c4c88167965e931c660cd0b1851e16f5ac6a35adaa2a16ee01eeab9f3dced50"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}